{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for species classification - OneForest\n",
    "\n",
    "Context: A 4-block CNN Model (called Model Basic) is used to do species classification: the resulting datasets obtained after mapping ground and drone data using Nearest Neighbours, Graph Matching Networks or an Optimal Transport method, is used for training the CNN to do species classification.\n",
    "\n",
    "For training, we give as input image patches of the trees. The labels are the species (scientific name of the trees).\n",
    "The notebook first defines functions to produce patches (as numpy arrays) and creates the patches and labels for Ecuador and NEON datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dropout, InputLayer, MaxPool2D\n",
    "from tensorflow.keras import optimizers, models\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "from deepforest import utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.color\n",
    "import skimage.io\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "torch.manual_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "package = os.path.dirname(os.getcwd())\n",
    "sys.path.append(package)\n",
    "sys.path.append(package + '/utils')\n",
    "sys.path\n",
    "from utils.deepforest_detection import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecuador dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('Ecuador/results/Gromov-Wasserstein Greedy_final_matching.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pos = final[final['is_musacea_g'] == 0]\n",
    "final_neg = final[final['is_musacea_g'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_to_csv(directory, name, train_on_resized = True):\n",
    "    xml = get_data(os.path.join(os.getcwd(), directory,\"{}.xml\".format(name)))\n",
    "    hand_annotations = utilities.xml_to_annotations(xml)\n",
    "    hand_annotations.to_csv(os.path.join(os.getcwd(), directory,\"hand_{}.csv\".format(name)),index=False, header=None)\n",
    "    return hand_annotations\n",
    "\n",
    "def get_patches(path_to_img, boxes):\n",
    "    # read image, based on command line filename argument;\n",
    "    # read the image as grayscale from the outset\n",
    "    patches = []\n",
    "\n",
    "    image = skimage.io.imread(path_to_img)\n",
    "\n",
    "    for index, row in boxes.iterrows():\n",
    "        tree = image[int(row.ymin):int(row.ymax), int(row.xmin):int(row.xmax)]\n",
    "        if tree.shape == (201,312,3):\n",
    "            continue\n",
    "        patches.append(tree)\n",
    "    return(patches)\n",
    "\n",
    "def resize_patches(patches):\n",
    "    n = len(patches)\n",
    "    print(n)\n",
    "    resized_patches = []\n",
    "    for j in range(n):\n",
    "        resized_patch = cv2.resize(np.array(patches[j], dtype = np.float32), (200,200))\n",
    "        resized_patches.append(resized_patch)\n",
    "    return(np.array(resized_patches))\n",
    "\n",
    "def patch_match(final):\n",
    "    list_tiles = np.unique(final['img_path'])\n",
    "    patches = []\n",
    "    for path in list_tiles:\n",
    "        sub = final[final.img_path == path]\n",
    "        site = path.split('_')[0]\n",
    "        path_to_img = os.path.join(os.getcwd(), 'Ecuador/images/{}/{}'.format(site, path))\n",
    "        boxes = sub[['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "        patch = get_patches(path_to_img, boxes)\n",
    "        b = np.array(patch)\n",
    "        if b.shape[0] == 1 | len(b.shape)==3:\n",
    "            continue\n",
    "        patches.extend(patch)\n",
    "    return(np.array(patches))\n",
    "\n",
    "def get_patches_and_labels(directory, name, path_to_img, boxes):\n",
    "    # read image, based on command line filename argument;\n",
    "    # read the image as grayscale from the outset\n",
    "    patches = []\n",
    "    labels = []\n",
    "    image = skimage.io.imread(path_to_img)\n",
    "\n",
    "    for index, row in boxes.iterrows():\n",
    "        tree = image[int(row.ymin):int(row.ymax), int(row.xmin):int(row.xmax)]\n",
    "        tree = cv2.resize(tree, (200, 200))\n",
    "        plt.imshow(tree)\n",
    "        plt.show()\n",
    "        labels.append(input('Is it a Musacea? '))\n",
    "        patches.append(tree)\n",
    "        \n",
    "    patches = np.array(patches)\n",
    "    labels = np.array(labels)\n",
    "    np.save('cnn/test2/labels.npy', labels)\n",
    "    np.save('cnn/test2/patches.npy', patches)\n",
    "    \n",
    "    boxes_test['labels'] = labels\n",
    "    boxes_test.to_csv(os.path.join(os.getcwd(), directory,\"hand_{}.csv\".format(name)),index=False, header=None)\n",
    "    return(patches, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patches_pos = patch_match(final_pos)\n",
    "patches_neg = patch_match(final_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos = len(patches_pos)\n",
    "n_neg = len(patches_neg)\n",
    "n_pos, n_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_pos = resize_patches(np.array(patches_pos))\n",
    "patches_neg = resize_patches(np.array(patches_neg))\n",
    "\n",
    "np.save('Ecuador/cnn/train_gw/patches_pos.npy', patches_pos)\n",
    "np.save('Ecuador/cnn/train_gw/patches_neg.npy', patches_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.array([0]*n_pos)\n",
    "y_neg = np.array([1]*n_neg)\n",
    "\n",
    "X = np.concatenate((patches_pos, patches_neg), axis=0)\n",
    "y = np.concatenate((y_pos, y_neg), axis=0)\n",
    "\n",
    "randomize = np.arange(len(X))\n",
    "np.random.shuffle(randomize)\n",
    "X = X[randomize]\n",
    "y = y[randomize]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_test = convert_xml_to_csv('cnn/test2', 'test_example_2', train_on_resized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'cnn/test2'\n",
    "path_to_img_test = os.path.join(os.getcwd(), 'cnn/test2/test_example_2.png')\n",
    "\n",
    "# Label patches: 0 if musacea; 1 otherwise\n",
    "X_test, labels_test = get_patches_and_labels('cnn/test2', 'test_example_2', path_to_img_test, boxes_test)  \n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('cnn/test/patches.npy')\n",
    "y_true = np.load('cnn/test/labels.npy')\n",
    "y_true = y_true.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches_and_labels_neon(final):\n",
    "    # read image, based on command line filename argument;\n",
    "    # read the image as grayscale from the outset\n",
    "    patches = []\n",
    "    labels = []\n",
    "    \n",
    "    if 'img_path_d' in final.columns:\n",
    "        final = final.rename(columns = {'img_path_d': 'img_path'})\n",
    "\n",
    "    for index, row in final.iterrows():\n",
    "        src = rasterio.open(os.path.join('NEON/images', row.img_path))\n",
    "        raster = src.read()\n",
    "        image = reshape_as_image(raster)\n",
    "        tree = image[int(row.ymin):int(row.ymax), int(row.xmin):int(row.xmax)].astype(int)\n",
    "        patches.append(tree)\n",
    "        labels.append(row.scientificName)\n",
    "    return(patches, labels)\n",
    "\n",
    "def get_height_labels_neon(final):\n",
    "    labels = []\n",
    "    \n",
    "    if 'img_path_d' in final.columns:\n",
    "        final = final.rename(columns = {'img_path_d': 'img_path'})\n",
    "\n",
    "    for index, row in final.iterrows():\n",
    "        labels.append(row.height)\n",
    "    return(labels)\n",
    "\n",
    "def get_diameter_labels_neon(final):\n",
    "    labels = []\n",
    "    \n",
    "    if 'img_path_d' in final.columns:\n",
    "        final = final.rename(columns = {'img_path_d': 'img_path'})\n",
    "\n",
    "    for index, row in final.iterrows():\n",
    "        labels.append(row.stemDiameter)\n",
    "    return(labels)\n",
    "\n",
    "\n",
    "def get_patches_and_labels_idtree(final):\n",
    "    # read image, based on command line filename argument;\n",
    "    # read the image as grayscale from the outset\n",
    "    patches = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in final.iterrows():\n",
    "        src = rasterio.open(os.path.join('IDTrees', row.rgb_path))\n",
    "        raster = src.read()\n",
    "        image = reshape_as_image(raster)\n",
    "        if row.site_id == 'ESALQ':\n",
    "            tree = image[:,:,:3].astype(int)\n",
    "        else:\n",
    "            tree = image[int(row.ymin):int(row.ymax), int(row.xmin):int(row.xmax)].astype(int)\n",
    "        patches.append(tree)\n",
    "        labels.append(row.scientific_name)\n",
    "    return(patches, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training patches and labels on NEON real (ground and drone data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv('NEON/results/Nearest Neighbours_final_matching.csv', index_col = 0)\n",
    "patches, labels = get_patches_and_labels_neon(final)\n",
    "np.save('NEON/cnn/train/patches_nn.npy', patches)\n",
    "np.save('NEON/cnn/train/labels_nn.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('NEON/results/Optimal Transport Non-Greedy_final_matching.csv', index_col = 0)\n",
    "patches, labels = get_patches_and_labels_neon(final)\n",
    "np.save('NEON/cnn/train/patches_ot_non_greedy.npy', patches)\n",
    "np.save('NEON/cnn/train/labels_ot_non_greedy.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('NEON/results/Optimal Transport Greedy_final_matching.csv', index_col = 0)\n",
    "patches, labels = get_patches_and_labels_neon(final)\n",
    "np.save('NEON/cnn/train/patches_ot_greedy.npy', patches)\n",
    "np.save('NEON/cnn/train/labels_ot_greedy.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('NEON/results/Graph Matching Network_final_matching.csv', index_col = 0)\n",
    "patches, labels = get_patches_and_labels_neon(final)\n",
    "np.save('NEON/cnn/train/patches_gmn.npy', patches)\n",
    "np.save('NEON/cnn/train/labels_gmn.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('NEON/results/Gromov-Wasserstein Greedy_final_matching.csv', index_col = 0)\n",
    "patches, labels = get_patches_and_labels_neon(final)\n",
    "np.save('NEON/cnn/train/patches_gw.npy', patches)\n",
    "np.save('NEON/cnn/train/labels_gw.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training patches and labels on NEON synthetic (noise added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the NEON patches and species labels from the different datasets obtained after mapping ground and drone data\n",
    "dir = 'NEON/results'\n",
    "for file in os.listdir(dir):\n",
    "    if file.startswith('final'):\n",
    "        sigma = file.split('_')[3]\n",
    "        method = file.split('_')[1]\n",
    "        path_file = os.path.join(dir, file)\n",
    "        final = pd.read_csv(path_file, index_col = 0)\n",
    "        patches, labels = get_patches_and_labels_neon(final)\n",
    "        np.save('NEON/cnn/train/patches_{}_sigma_{}.npy'.format(method, sigma), patches)\n",
    "        np.save('NEON/cnn/train/labels_{}_sigma_{}.npy'.format(method, sigma), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the height labels\n",
    "dir = 'NEON/results'\n",
    "for file in os.listdir(dir):\n",
    "    if file.startswith('final'):\n",
    "        sigma = file.split('_')[3]\n",
    "        method = file.split('_')[1]\n",
    "        path_file = os.path.join(dir, file)\n",
    "        final = pd.read_csv(path_file, index_col = 0)\n",
    "        \n",
    "        heights = get_height_labels_neon(final)\n",
    "        np.save('NEON/cnn/train/heights_{}_sigma_{}.npy'.format(method, sigma), heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the diameter labels\n",
    "dir = 'NEON/results'\n",
    "for file in os.listdir(dir):\n",
    "    if file.startswith('final'):\n",
    "        sigma = file.split('_')[3]\n",
    "        method = file.split('_')[1]\n",
    "        path_file = os.path.join(dir, file)\n",
    "        final = pd.read_csv(path_file, index_col = 0)\n",
    "        \n",
    "        diameters = get_diameter_labels_neon(final)\n",
    "        np.save('NEON/cnn/train/diameters_{}_sigma_{}.npy'.format(method, sigma), diameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Set correponds to the true matching\n",
    "true_matching = pd.read_csv('NEON/data/true_matching.csv', index_col = 0)\n",
    "            \n",
    "new_df = true_matching.copy()\n",
    "n = len(new_df)\n",
    "N = int(n*0.2)\n",
    "Test = []\n",
    "for i in range(5):\n",
    "    test = new_df.sample(n=N, random_state=1)\n",
    "    Test.append(test)\n",
    "    new_df = new_df.drop(test.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Test)):\n",
    "    patches, labels = get_patches_and_labels_neon(Test[i])\n",
    "    np.save('NEON/cnn/test/patches_test_{}.npy'.format(i+1), patches)\n",
    "    np.save('NEON/cnn/test/labels_test_{}.npy'.format(i+1), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Test)):\n",
    "    heights = get_height_labels_neon(Test[i])\n",
    "    np.save('NEON/cnn/test/heights_test_{}.npy'.format(i+1), heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Test)):\n",
    "    diameters = get_diameter_labels_neon(Test[i])\n",
    "    np.save('NEON/cnn/test/diameters_test_{}.npy'.format(i+1), diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = true_matching['height'].to_numpy()\n",
    "b = true_matching['stemDiameter'].to_numpy()\n",
    "\n",
    "a = a[~np.isnan(a)]\n",
    "b = b[~np.isnan(b)]\n",
    "\n",
    "print(len(a), len(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 200\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=6, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a sequential model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(200, 200, 3)))\n",
    "\n",
    "# 1st conv block\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "# 2nd conv block\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd conv block\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# compile model\n",
    "#opt = tf.keras.optimizers.SGD(lr=0.01)\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "#opt = tf.keras.optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restnet = ResNet50(include_top=False, weights=None, input_shape=(200,200,3))\n",
    "output = restnet.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "restnet = Model(restnet.input, output=output)\n",
    "for layer in restnet.layers:\n",
    "    layer.trainable = True\n",
    "restnet.summary()\n",
    "\n",
    "model_resnet = Sequential()\n",
    "model_resnet.add(restnet)\n",
    "model_resnet.add(Dense(512, activation='relu', input_dim=(200,200,3)))\n",
    "model_resnet.add(Dropout(0.3))\n",
    "model_resnet.add(Dense(512, activation='relu'))\n",
    "model_resnet.add(Dropout(0.3))\n",
    "model_resnet.add(Dense(1, activation='sigmoid'))\n",
    "model_resnet.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "model_resnet.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOBILENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(include_top = False, weights=None, input_shape=(200, 200, 3))\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "preds =  tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)(x)\n",
    "\n",
    "model=tf.keras.Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(lr=0.01)\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "#opt = tf.keras.optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEON BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=6, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=0.01))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(63, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}