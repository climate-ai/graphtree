{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of noise on the accuracy of OneForest mapping method\n",
    "\n",
    "We evaluate the effect of increasing the noise in ground data and drone on the accuracy of the different mapping methods to recover the true mapping bewtween the two data sources. For evaluation, we create synthetic datasets on scratch or based on real drone images from Ecuador or NEON dtasets.\n",
    "\n",
    "We can produce noisy data in different ways:\n",
    "- GPS noise in ground data as random gaussian noise.\n",
    "- GPS noise in drone data as a uniform shift, since all the trees from the same drone image are identically noisy.\n",
    "- Noise in inexact tree detection of DeepForest: we play on the threshold score of deepforest, defined as the score at which we accept bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import ot\n",
    "import ot.plot\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/anaconda3/lib/python36.zip',\n",
       " '/anaconda3/lib/python3.6',\n",
       " '/anaconda3/lib/python3.6/lib-dynload',\n",
       " '/Users/kenzaamara/.local/lib/python3.6/site-packages',\n",
       " '/anaconda3/lib/python3.6/site-packages',\n",
       " '/anaconda3/lib/python3.6/site-packages/aeosa',\n",
       " '/Users/kenzaamara/Documents/ETH Zurich/Master/Master Thesis/code/oneforest',\n",
       " '/anaconda3/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/kenzaamara/.ipython',\n",
       " '/Users/kenzaamara/PycharmProjects/oneforest',\n",
       " '/Users/kenzaamara/PycharmProjects/oneforest/utils']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "package = os.path.dirname(os.getcwd())\n",
    "sys.path.append(package)\n",
    "sys.path.append(package + '/utils')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils \n",
    "\n",
    "from utils.citizen_science import *\n",
    "from utils.extract_features import *\n",
    "\n",
    "from utils.deepforest_detection import *\n",
    "from utils.deepforest_evaluation import *\n",
    "\n",
    "from utils.visualisation import *\n",
    "from utils.plot_folium import *\n",
    "from utils.plot_density import *\n",
    "\n",
    "from utils.mapping import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_nn(X_ground_nn, X_drone_nn):\n",
    "    \n",
    "    n = len(X_ground_nn)\n",
    "    m = len(X_drone_nn)\n",
    "    X = np.concatenate([X_ground_nn, X_drone_nn])\n",
    "    \n",
    "    dists, idxs = nearest_neighbors(X, nbr_neighbors=n+m)\n",
    "\n",
    "    ground_index = []\n",
    "    for i in range(n):\n",
    "        p = 1\n",
    "        id = X[i,2]\n",
    "        while(X[idxs[i][p], 2] == id):\n",
    "            p += 1\n",
    "        j = idxs[i,p]\n",
    "        ground_index.append(j-n)\n",
    "    ground_index = np.array(ground_index, dtype = np.int32)\n",
    "    return(ground_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate increasing random noise in ground data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuador synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = pd.read_csv('Ecuador/evaluation/hand_test_example.csv', names = ['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'label', 'is_musacea'])\n",
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes['x'] = (boxes.xmin + boxes.xmax)/2\n",
    "boxes['y'] = (boxes.ymin + boxes.ymax)/2\n",
    "boxes['img_path'] = 'Flora Pluas RGB_7_3800_7600_7800_11600.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_data = pd.read_csv('Ecuador/features/ortho_data.csv')\n",
    "\n",
    "rx_meters = []\n",
    "ry_meters = []\n",
    "\n",
    "for index, row in site_data.iterrows():\n",
    "    height_pxl = (row.lat_max - row.lat_min)/row.ratio_y\n",
    "    length_pxl = (row.lon_max - row.lon_min)/row.ratio_x\n",
    "    \n",
    "    coords_1 = (row.lat_min, row.lon_min)\n",
    "    coords_2 = (row.lat_max, row.lon_min)\n",
    "\n",
    "    height = geopy.distance.vincenty(coords_1, coords_2).km*1000\n",
    "\n",
    "    coords_1 = (row.lat_min, row.lon_min)\n",
    "    coords_2 = (row.lat_min, row.lon_max)\n",
    "\n",
    "    length = geopy.distance.vincenty(coords_1, coords_2).km*1000\n",
    "    \n",
    "    rx_meters.append(length_pxl/length)\n",
    "    ry_meters.append(height_pxl/height)\n",
    "    \n",
    "print(np.mean(rx_meters))\n",
    "print(np.mean(ry_meters))\n",
    "\n",
    "# 1 meter is represented by approximatively 160 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe what is the effect of the random gaussian noise on ground data\n",
    "img_path = 'Ecuador/evaluation/test_example.tif'\n",
    "im = cv2.imread(img_path)\n",
    "annot = box_to_annotation(boxes[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy())\n",
    "im = draw_annotations(im, annot, color=(0, 0, 255), label_to_name=None, plot = False, cv2_authorized = False, thickness = 4)\n",
    "\n",
    "X_d = boxes[['x', 'y']].to_numpy()\n",
    "X_g = boxes[['x', 'y']].to_numpy()\n",
    "\n",
    "sigmas = np.array([0.5, 1.5, 3])*160\n",
    "\n",
    "\n",
    "n = len(X_d)\n",
    "for k in range(len(sigmas)):\n",
    "    noise = np.random.normal(0, sigmas[k], (n, 2))\n",
    "    X_ground = X_g + noise\n",
    "    X_drone = X_d\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.scatter(x=X_ground[i][0], y=X_ground[i][1], c='b', s=40)\n",
    "        plt.scatter(x=X_drone[i][0], y=X_drone[i][1], c='r', s=40)\n",
    "\n",
    "        plt.plot([X_ground[i][0], X_drone[i][0]], [X_ground[i][1], X_drone[i][1]], color='red', marker=None, linewidth=0.5, markersize=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mapping(X_drone, X_ground, idx):\n",
    "\n",
    "    img_path = 'Ecuador/evaluation/test_example.tif'\n",
    "    im = cv2.imread(img_path)\n",
    "    annot = box_to_annotation(boxes[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy())\n",
    "    im = draw_annotations(im, annot, color=(0, 0, 255), label_to_name=None, plot = False, cv2_authorized = False, thickness = 4)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    X_drone_pred = X_drone[idx]\n",
    "    print(idx)\n",
    "    n = len(X_ground)\n",
    "    y_true = range(n)\n",
    "    res = y_true == idx\n",
    "    print(res)\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.scatter(x=X_ground[i][0], y=X_ground[i][1], c='b', s=40)\n",
    "        plt.scatter(x=X_drone[i][0], y=X_drone[i][1], c='r', s=40)\n",
    "\n",
    "        #plt.plot([X_ground[i][0], X_drone[i][0]], [X_ground[i][1], X_drone[i][1]], color='red', marker=\"o\", linewidth=0.5, markersize=2)\n",
    "        \n",
    "        if res[i] == True:\n",
    "            plt.plot([X_ground[i][0], X_drone_pred[i][0]], [X_ground[i][1], X_drone_pred[i][1]], color='green', marker=None, linewidth=1)\n",
    "        if res[i] == False:\n",
    "            plt.plot([X_ground[i][0], X_drone_pred[i][0]], [X_ground[i][1], X_drone_pred[i][1]], color='red', marker=None, linewidth=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_noise(sigmas, X_d, mus_d=None, mus_g=None):\n",
    "    \n",
    "    Acc_nn = []\n",
    "    Acc_ot_non_greedy = []\n",
    "    Acc_ot_greedy = []\n",
    "    Acc_ot_cnn = []\n",
    "    Acc_gw = []\n",
    "    \n",
    "\n",
    "    n = len(X_d)\n",
    "    for k in range(len(sigmas)):\n",
    "        sigma = sigmas[k]\n",
    "        noise = np.random.normal(0, sigma, (n, 2))\n",
    "        X_ground = X_d + noise\n",
    "        X_drone = X_d\n",
    "        \n",
    "        y_true = range(n)\n",
    "\n",
    "        # Nearest Neighbours\n",
    "        X_drone_nn = np.hstack((X_drone, np.zeros((n, 1), dtype=np.int32)))\n",
    "        X_ground_nn = np.hstack((X_ground, np.zeros((n, 1), dtype=np.int32)+1))\n",
    "        idx = index_nn(X_ground_nn, X_drone_nn)\n",
    "        Acc_nn.append(accuracy_score(y_true, idx))\n",
    "        #plot_mapping(X_drone, X_ground, idx)\n",
    "\n",
    "        # OT ground to drone\n",
    "        G = OT_sinkhorn(X_drone, X_ground, lambd = 0.01)\n",
    "        idx = np.argmax(G, axis = 0)\n",
    "        Acc_ot_non_greedy.append(accuracy_score(y_true, idx))\n",
    "        #plot_mapping(X_drone, X_ground, idx)\n",
    "        \n",
    "        # OT greedy\n",
    "        G = OT_sinkhorn(X_drone, X_ground, lambd = 0.01)\n",
    "        cost = -G*10e4\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        Acc_ot_greedy.append(accuracy_score(y_true, col_ind))\n",
    "        #plot_mapping_inv(X_drone, X_ground, idx)\n",
    "        \n",
    "        \n",
    "        if mus_g is not None:\n",
    "            # OT with CNN filtering ground to drone\n",
    "            G = OT_scores_sinkhorn(X_drone, X_ground, mus_d, mus_g, mu = 1, lambd = 0.01)\n",
    "            cost = -G\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "            Acc_ot_cnn.append(accuracy_score(y_true, col_ind))\n",
    "        \n",
    "        \n",
    "        # Gromov-Wasserstein\n",
    "        G = gromov_wasserstein(X_drone, X_ground)\n",
    "        idx = np.argmax(G, axis = 0)\n",
    "        Acc_gw.append(accuracy_score(y_true, idx))\n",
    "        \n",
    "        \n",
    "    return(Acc_nn, Acc_ot_non_greedy, Acc_ot_greedy, Acc_ot_cnn, Acc_gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ecuador/annotations/final_annotations.csv', index_col = 0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ecuador/evaluation/hand_test_example.csv', names = ['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'label', 'is_musacea'])\n",
    "df[['x', 'y']] = df.apply(lambda x: [get_center(x.xmin,x.xmax), get_center(x.ymin,x.ymax)], axis=1, result_type=\"expand\")\n",
    "\n",
    "df.img_path = 'Flora Pluas RGB_7_3800_7600_7800_11600.png'\n",
    "\n",
    "cnn_model = tensorflow.keras.models.load_model('Ecuador/cnn/cnn_model')\n",
    "site_name = 'Flora Pluas RGB'\n",
    "df = predict_musacea(df, site_name, cnn_model)\n",
    "\n",
    "# True is_musacea ('is_musacea_g')\n",
    "\n",
    "y_true = np.load('Ecuador/cnn/test/labels.npy')\n",
    "y_true = y_true.astype(int)\n",
    "df['is_musacea_g'] = y_true\n",
    "\n",
    "df = df.rename(columns = {\"is_musacea\": \"is_musacea_d\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "n = len(new_df)\n",
    "N = int(n*0.2)\n",
    "Test = []\n",
    "for i in range(5):\n",
    "    test = new_df.sample(n=N, random_state=1)\n",
    "    Test.append(test)\n",
    "    new_df = new_df.drop(test.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.array([0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4])*160\n",
    "\n",
    "def run_evaluation_test_Ecuador_tile(Test, sigmas):\n",
    "    LIST_ACC_TEST = []\n",
    "    res = pd.DataFrame(columns=['sigma', 'accuracy', 'method', 'test'])\n",
    "    k = 0\n",
    "    for df_test in Test:\n",
    "        k +=1\n",
    "        X_d = df_test[['x', 'y']].to_numpy()\n",
    "\n",
    "        mus_d = df_test.is_musacea_d.to_numpy()\n",
    "        mus_d = np.vstack(mus_d).reshape(-1)\n",
    "        mus_g = df_test.is_musacea_g.to_numpy()\n",
    "\n",
    "        Acc_nn, Acc_ot_non_greedy, Acc_ot_greedy, Acc_ot_cnn, Acc_gw = evaluation_noise(sigmas, X_d, mus_d, mus_g)\n",
    "\n",
    "        ACC_TEST = [Acc_nn, Acc_ot_non_greedy, Acc_ot_greedy, Acc_ot_cnn, Acc_gw]\n",
    "        methods = ['NN', 'OT non greedy', 'OT greedy', 'OT CNN', 'GW']\n",
    "        \n",
    "        n = len(sigmas)\n",
    "        for i in range(len(methods)):\n",
    "            df_sup = pd.DataFrame()\n",
    "            df_sup['sigma'] = sigmas/160\n",
    "            df_sup['accuracy'] = ACC_TEST[i]\n",
    "            df_sup['method'] = [methods[i]]*n\n",
    "            df_sup['test'] = [k]*n\n",
    "            res = pd.concat([res, df_sup], ignore_index=True)\n",
    "            \n",
    "        #print(\"ACC_TEST is: \", ACC_TEST)\n",
    "        #LIST_ACC_TEST.append(ACC_TEST)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_Ecuador = run_evaluation_test_Ecuador_tile(Test, sigmas)\n",
    "res_Ecuador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=res_Ecuador, x=\"sigma\", y=\"accuracy\", hue=\"method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_Ecuador.to_csv('Ecuador/results/evaluation_nn_ot_gw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Ecuador/results/evaluation_nn_ot_gw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-c0e176003de9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mres_Ecuador\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Ecuador/results/evaluation_nn_ot_gw.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mres_Ecuador\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres_Ecuador\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mres_Ecuador\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethod\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m'OT non greedy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mres_Ecuador\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres_Ecuador\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'OT greedy'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m'OT on GPS position'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'OT CNN'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m'OT on GPS position + Tree species'\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    686\u001B[0m     )\n\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 688\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    689\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 454\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    946\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    947\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 948\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    949\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    950\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1178\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1179\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1180\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1181\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1182\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   2008\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2009\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2010\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2011\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2012\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Ecuador/results/evaluation_nn_ot_gw.csv'"
     ]
    }
   ],
   "source": [
    "res_Ecuador = pd.read_csv('Ecuador/results/evaluation_nn_ot_gw.csv')\n",
    "res_Ecuador = res_Ecuador[res_Ecuador.method != 'OT non greedy']\n",
    "res_Ecuador = res_Ecuador.replace({'OT greedy':'OT on GPS position', 'OT CNN':'OT on GPS position + Tree species'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_Ecuador_gmn = pd.read_csv('Ecuador/results/evaluation_gmn.csv')\n",
    "res_Ecuador = pd.concat([res_Ecuador, res_Ecuador_gmn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 10])\n",
    "ax.set_xlabel('sigma (m)')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Evaluation of Mapping Methods when Increasing Noise in GPS coordinates of Ground Measurements\\n (Synthetic Dataset based on 105 trees in Ecuador)')\n",
    "\n",
    "sns.lineplot(data=res_Ecuador, x=\"sigma\", y=\"accuracy\", hue=\"method\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEON synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NEON/data/true_matching.csv', index_col = 0)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scientificName.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty map zoomed in on \n",
    "m = folium.Map(location=[30, 120], zoom_start=13,tiles='CartoDBPositron')\n",
    "\n",
    "\n",
    "X_street = df[['plotLatitude', 'plotLongitude']].to_numpy()\n",
    "#add markers\n",
    "\n",
    "for i in range(len(X_street)):\n",
    "    #folium.Marker(each, icon=folium.Icon(color='blue', icon='cloud')).add_to(m)\n",
    "    #print(df.scientificName.loc[i], df.stemDiameter.loc[i], df.height.loc[i])\n",
    "    #my_string = '<b>Species</b>: {}, <br><b>Diameter</b>: {},  <br><b>Height</b>: {}'.format(df.scientificName.loc[i], df.stemDiameter.loc[i], df.height.loc[i])  \n",
    "    #folium.CircleMarker(location=X_street[i], radius=3, weight = 0, fill_color='blue', fill_opacity=0.4, popup = Popup(my_string)).add_to(m)\n",
    "    folium.CircleMarker(location=X_street[i], radius=3, weight = 0, fill_color='red', fill_opacity=0.4).add_to(m)\n",
    "\n",
    "folium.TileLayer(\n",
    "        tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "        attr = 'Esri',\n",
    "        name = 'Esri Satellite',\n",
    "        overlay = False,\n",
    "        control = True\n",
    "    ).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot on one tile 'BART_036.tif'\n",
    "\n",
    "sub = df[df.img_path == 'BART_036.tif']\n",
    "X_drone = sub[['x', 'y']].to_numpy()\n",
    "print(len(X_drone))\n",
    "n = len(X_drone)\n",
    "\n",
    "sigma = 30\n",
    "noise = np.random.normal(0, sigma, (n, 2))\n",
    "X_ground = X_drone + noise\n",
    "\n",
    "src = rasterio.open('NEON/images/BART_036.tif')\n",
    "raster = src.read()\n",
    "image = reshape_as_image(raster)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(image.astype(int))\n",
    "\n",
    "for i in range(len(X_drone)):\n",
    "    plt.scatter(x=X_drone[i][0], y=X_drone[i][1], c='r', s=40)\n",
    "    plt.scatter(x=X_ground[i][0], y=X_ground[i][1], c='b', s=40)\n",
    "    plt.plot([X_ground[i][0], X_drone[i][0]], [X_ground[i][1], X_drone[i][1]], color='red', marker=None, linewidth=0.5, markersize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_noise(sigmas, X_drone):\n",
    "    \n",
    "    Acc_nn = []\n",
    "    Acc_ot_non_greedy = []\n",
    "    Acc_ot_greedy = []\n",
    "    Acc_ot_cnn = []\n",
    "    Acc_gw = []\n",
    "    \n",
    "\n",
    "    n = len(X_drone)\n",
    "    for k in range(len(sigmas)):\n",
    "        noise = np.random.normal(0, sigmas[k], (n, 2))\n",
    "        X_ground = X_drone + noise\n",
    "        \n",
    "        y_true = range(n)\n",
    "\n",
    "        # Nearest Neighbours\n",
    "        X_drone_nn = np.hstack((X_drone, np.zeros((n, 1), dtype=np.int32)))\n",
    "        X_ground_nn = np.hstack((X_ground, np.zeros((n, 1), dtype=np.int32)+1))\n",
    "        idx = index_nn(X_ground_nn, X_drone_nn)\n",
    "        Acc_nn.append(accuracy_score(y_true, idx))\n",
    "        #plot_mapping(X_drone, X_ground, idx)\n",
    "\n",
    "        # OT ground to drone\n",
    "        G = OT_sinkhorn(X_drone, X_ground, lambd = 0.01)\n",
    "        idx = np.argmax(G, axis = 0)\n",
    "        Acc_ot_non_greedy.append(accuracy_score(y_true, idx))\n",
    "        #plot_mapping(X_drone, X_ground, idx)\n",
    "        \n",
    "        # OT greedy\n",
    "        G = OT_sinkhorn(X_drone, X_ground, lambd = 0.01)\n",
    "        cost = -G*10e4\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        Acc_ot_greedy.append(accuracy_score(y_true, col_ind))\n",
    "        #plot_mapping_inv(X_drone, X_ground, idx)\n",
    "        \n",
    "        \n",
    "        # Gromov-Wasserstein\n",
    "        G = gromov_wasserstein(X_drone, X_ground)\n",
    "        idx = np.argmax(G, axis = 0)\n",
    "        Acc_gw.append(accuracy_score(y_true, idx))\n",
    "        \n",
    "        \n",
    "    return(Acc_nn, Acc_ot_non_greedy, Acc_ot_greedy, Acc_ot_cnn, Acc_gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.array([0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4])\n",
    "\n",
    "def run_evaluation_test(Test, sigmas):\n",
    "    LIST_ACC_TEST = []\n",
    "    res = pd.DataFrame(columns=['sigma', 'accuracy', 'method', 'test'])\n",
    "    k = 0\n",
    "    for df_test in Test:\n",
    "        k +=1\n",
    "        Acc_nn_sites = []\n",
    "        Acc_ot_non_greedy_sites = []\n",
    "        Acc_ot_greedy_sites = []\n",
    "        Acc_gw_sites = []\n",
    "        list_site = np.unique(df_test['site'].to_numpy())\n",
    "        for name in list_site:\n",
    "            site = df_test[df_test.site == name]\n",
    "            \n",
    "            X_drone = site[['X', 'Y']].to_numpy()\n",
    "            if(len(site)>1):\n",
    "                Acc_nn, Acc_ot_non_greedy, Acc_ot_greedy,_, Acc_gw = evaluation_noise(sigmas, X_drone)\n",
    "                Acc_nn_sites.append(Acc_nn)\n",
    "                Acc_ot_non_greedy_sites.append(Acc_ot_non_greedy)\n",
    "                Acc_ot_greedy_sites.append(Acc_ot_greedy)\n",
    "                Acc_gw_sites.append(Acc_gw)\n",
    "        \n",
    "        ACC_TEST = [np.mean(Acc_nn_sites, axis = 0), np.mean(Acc_ot_non_greedy_sites, axis = 0), np.mean(Acc_ot_greedy_sites, axis = 0), np.mean(Acc_gw_sites, axis = 0)]\n",
    "        methods = ['NN', 'OT non greedy', 'OT greedy', 'GW']\n",
    "        n = len(sigmas)\n",
    "        for i in range(len(methods)):\n",
    "            df_sup = pd.DataFrame()\n",
    "            df_sup['sigma'] = sigmas\n",
    "            df_sup['accuracy'] = ACC_TEST[i]\n",
    "            df_sup['method'] = [methods[i]]*n\n",
    "            df_sup['test'] = [k]*n\n",
    "            res = pd.concat([res, df_sup], ignore_index=True)\n",
    "            \n",
    "        #print(\"ACC_TEST is: \", ACC_TEST)\n",
    "        #LIST_ACC_TEST.append(ACC_TEST)\n",
    "    return(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat 5 testing folds to have a variance and a mean for the mapping accuracy\n",
    "new_df = df.copy()\n",
    "n = len(new_df)\n",
    "N = int(n*0.2)\n",
    "Test = []\n",
    "for i in range(5):\n",
    "    test = new_df.sample(n=N, random_state=1)\n",
    "    Test.append(test)\n",
    "    new_df = new_df.drop(test.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_NEON = run_evaluation_test(Test, sigmas)\n",
    "res_NEON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_NEON.to_csv('NEON/results/evaluation_nn_ot_gw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_NEON = pd.read_csv('NEON/results/evaluation_nn_ot_gw.csv')\n",
    "res_NEON = res_NEON[res_NEON.method != 'OT non greedy']\n",
    "res_NEON = res_NEON.replace({'OT greedy':'OT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=res_NEON, x=\"sigma\", y=\"accuracy\", hue=\"method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_NEON_gmn = pd.read_csv('NEON/results/evaluation_gmn.csv')\n",
    "res_NEON = pd.concat([res_NEON, res_NEON_gmn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 10])\n",
    "ax.set_xlabel('sigma (m)')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Evaluation of Mapping Methods when Increasing Noise in GPS on a Synthetic Dataset\\n (3839 trees of NEON Dataset)')\n",
    "\n",
    "sns.lineplot(data=res_NEON, x=\"sigma\", y=\"accuracy\", hue=\"method\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise in Ground AND Drone data (GPS position) - purely synthetic dataset\n",
    "\n",
    "We generate points in a grid. We add random gaussian noise in ground data and a shift in drone data. We observe the ability of different mapping methods to recover the true mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the points based on a random Poisson-disk Sampling. Similar to the PPP, the Poisson-disk Sampling generates the points randomly, but ensures that the points are at least a distance d apart from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose up to k points around each reference point as candidates for a new\n",
    "# sample point\n",
    "k = 30\n",
    "\n",
    "# Minimum distance between samples\n",
    "r = 3\n",
    "\n",
    "width, height = 60, 45 # --> 200 points approximately \n",
    "#width, height = 25, 25 # --> 50 points approximately \n",
    "\n",
    "# Cell side length\n",
    "a = r/np.sqrt(2)\n",
    "# Number of cells in the x- and y-directions of the grid\n",
    "nx, ny = int(width / a) + 1, int(height / a) + 1\n",
    "\n",
    "# A list of coordinates in the grid of cells\n",
    "coords_list = [(ix, iy) for ix in range(nx) for iy in range(ny)]\n",
    "# Initilalize the dictionary of cells: each key is a cell's coordinates, the\n",
    "# corresponding value is the index of that cell's point's coordinates in the\n",
    "# samples list (or None if the cell is empty).\n",
    "cells = {coords: None for coords in coords_list}\n",
    "\n",
    "def get_cell_coords(pt):\n",
    "    \"\"\"Get the coordinates of the cell that pt = (x,y) falls in.\"\"\"\n",
    "\n",
    "    return int(pt[0] // a), int(pt[1] // a)\n",
    "\n",
    "def get_neighbours(coords):\n",
    "    \"\"\"Return the indexes of points in cells neighbouring cell at coords.\n",
    "\n",
    "    For the cell at coords = (x,y), return the indexes of points in the cells\n",
    "    with neighbouring coordinates illustrated below: ie those cells that could \n",
    "    contain points closer than r.\n",
    "\n",
    "                                     ooo\n",
    "                                    ooooo\n",
    "                                    ooXoo\n",
    "                                    ooooo\n",
    "                                     ooo\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dxdy = [(-1,-2),(0,-2),(1,-2),(-2,-1),(-1,-1),(0,-1),(1,-1),(2,-1),\n",
    "            (-2,0),(-1,0),(1,0),(2,0),(-2,1),(-1,1),(0,1),(1,1),(2,1),\n",
    "            (-1,2),(0,2),(1,2),(0,0)]\n",
    "    neighbours = []\n",
    "    for dx, dy in dxdy:\n",
    "        neighbour_coords = coords[0] + dx, coords[1] + dy\n",
    "        if not (0 <= neighbour_coords[0] < nx and\n",
    "                0 <= neighbour_coords[1] < ny):\n",
    "            # We're off the grid: no neighbours here.\n",
    "            continue\n",
    "        neighbour_cell = cells[neighbour_coords]\n",
    "        if neighbour_cell is not None:\n",
    "            # This cell is occupied: store this index of the contained point.\n",
    "            neighbours.append(neighbour_cell)\n",
    "    return neighbours\n",
    "\n",
    "def point_valid(pt):\n",
    "    \"\"\"Is pt a valid point to emit as a sample?\n",
    "\n",
    "    It must be no closer than r from any other point: check the cells in its\n",
    "    immediate neighbourhood.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cell_coords = get_cell_coords(pt)\n",
    "    for idx in get_neighbours(cell_coords):\n",
    "        nearby_pt = samples[idx]\n",
    "        # Squared distance between or candidate point, pt, and this nearby_pt.\n",
    "        distance2 = (nearby_pt[0]-pt[0])**2 + (nearby_pt[1]-pt[1])**2\n",
    "        if distance2 < r**2:\n",
    "            # The points are too close, so pt is not a candidate.\n",
    "            return False\n",
    "    # All points tested: if we're here, pt is valid\n",
    "    return True\n",
    "\n",
    "def get_point(k, refpt):\n",
    "    \"\"\"Try to find a candidate point relative to refpt to emit in the sample.\n",
    "\n",
    "    We draw up to k points from the annulus of inner radius r, outer radius 2r\n",
    "    around the reference point, refpt. If none of them are suitable (because\n",
    "    they're too close to existing points in the sample), return False.\n",
    "    Otherwise, return the pt.\n",
    "\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < k:\n",
    "        rho, theta = np.random.uniform(r, 2*r), np.random.uniform(0, 2*np.pi)\n",
    "        pt = refpt[0] + rho*np.cos(theta), refpt[1] + rho*np.sin(theta)\n",
    "        if not (0 <= pt[0] < width and 0 <= pt[1] < height):\n",
    "            # This point falls outside the domain, so try again.\n",
    "            continue\n",
    "        if point_valid(pt):\n",
    "            return pt\n",
    "        i += 1\n",
    "    # We failed to find a suitable point in the vicinity of refpt.\n",
    "    return False\n",
    "\n",
    "# Pick a random point to start with.\n",
    "pt = (np.random.uniform(0, width), np.random.uniform(0, height))\n",
    "samples = [pt]\n",
    "# Our first sample is indexed at 0 in the samples list...\n",
    "cells[get_cell_coords(pt)] = 0\n",
    "# ... and it is active, in the sense that we're going to look for more points\n",
    "# in its neighbourhood.\n",
    "active = [0]\n",
    "\n",
    "nsamples = 1\n",
    "# As long as there are points in the active list, keep trying to find samples.\n",
    "while active:\n",
    "    # choose a random \"reference\" point from the active list.\n",
    "    idx = np.random.choice(active)\n",
    "    refpt = samples[idx]\n",
    "    # Try to pick a new point relative to the reference point.\n",
    "    pt = get_point(k, refpt)\n",
    "    if pt:\n",
    "        # Point pt is valid: add it to the samples list and mark it as active\n",
    "        samples.append(pt)\n",
    "        nsamples += 1\n",
    "        active.append(len(samples)-1)\n",
    "        cells[get_cell_coords(pt)] = len(samples) - 1\n",
    "    else:\n",
    "        # We had to give up looking for valid points near refpt, so remove it\n",
    "        # from the list of \"active\" points.\n",
    "        active.remove(idx)\n",
    "\n",
    "plt.scatter(*zip(*samples), color='r', alpha=0.6, lw=0)\n",
    "plt.xlim(0, width)\n",
    "plt.ylim(0, height)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_shift(x, shft):\n",
    "    return x + shft\n",
    "\n",
    "def noise_random(x, std):\n",
    "    noise = np.random.normal(0, std, (len(x), 2))\n",
    "    x = x + noise\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_nearest_neighbours(x_drone, x_ground):\n",
    "    n = len(x_drone)\n",
    "    x_drone_nn = np.hstack((x_drone, np.zeros((n, 1), dtype=np.int32)))\n",
    "    x_ground_nn = np.hstack((x_ground, np.zeros((n, 1), dtype=np.int32)+1))\n",
    "    idx = index_nn(x_ground_nn, x_drone_nn)\n",
    "    acc = accuracy_score(range(n), idx)\n",
    "    return acc\n",
    "\n",
    "def acc_optimal_transport_non_greedy(x_drone, x_ground):\n",
    "    n = len(x_drone)\n",
    "    G = OT_sinkhorn(x_drone, x_ground, lambd = 0.01)\n",
    "    idx = np.argmax(G, axis = 0)\n",
    "    acc = accuracy_score(range(n), idx)\n",
    "    return acc\n",
    "\n",
    "def acc_optimal_transport_greedy(x_drone, x_ground):\n",
    "    n = len(x_drone)\n",
    "    G = OT_sinkhorn(x_drone, x_ground, lambd = 0.01)\n",
    "    cost = -G*10e4\n",
    "    row_ind, col_ind = linear_sum_assignment(cost)\n",
    "    acc = accuracy_score(range(n), col_ind)\n",
    "    return acc\n",
    "\n",
    "def acc_gromov_wasserstein(x_drone, x_ground):\n",
    "    n = len(x_drone)\n",
    "    G = gromov_wasserstein(x_drone, x_ground)\n",
    "    idx = np.argmax(G, axis = 0)\n",
    "    acc = accuracy_score(range(n), idx)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_noise(samples, shifts, sigmas):\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "\n",
    "    n = len(samples)\n",
    "    \n",
    "    for s in range(len(shifts)):\n",
    "        for p in range(len(sigmas)):\n",
    "            std = sigmas[p]\n",
    "            shft = shifts[s]\n",
    "            \n",
    "            x_ground = noise_random(samples, std)\n",
    "            x_drone = noise_shift(samples, shft)\n",
    "    \n",
    "            # Nearest Neighbours\n",
    "            acc = acc_nearest_neighbours(x_drone, x_ground)\n",
    "            new_row = {'method':'NN', 'std':std, 'shift':shft, 'accuracy':acc}\n",
    "            #append row to the dataframe\n",
    "            res = res.append(new_row, ignore_index=True)\n",
    "\n",
    "            \n",
    "            # OT ground to drone\n",
    "            acc = acc_optimal_transport_non_greedy(x_drone, x_ground)\n",
    "            new_row = {'method':'OT non greedy', 'std':std, 'shift':shft, 'accuracy':acc}\n",
    "            #append row to the dataframe\n",
    "            res = res.append(new_row, ignore_index=True)\n",
    "\n",
    "            # OT greedy\n",
    "            acc = acc_optimal_transport_greedy(x_drone, x_ground)\n",
    "            new_row = {'method':'OT greedy', 'std':std, 'shift':shft, 'accuracy':acc}\n",
    "            #append row to the dataframe\n",
    "            res = res.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "            # Gromov-Wasserstein\n",
    "            acc_gromov_wasserstein(x_drone, x_ground)\n",
    "            new_row = {'method':'GW', 'std':std, 'shift':shft, 'accuracy':acc}\n",
    "            #append row to the dataframe\n",
    "            res = res.append(new_row, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shifts = np.array([0, 0.5, 1, 1.5, 2])\n",
    "#sigmas = np.array([0, 0.5, 1, 1.5, 2])\n",
    "\n",
    "shifts = np.linspace(0, 2, 11)\n",
    "sigmas = np.linspace(0, 2, 11)\n",
    "\n",
    "res = evaluation_noise(samples, shifts, sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('results/results_gps_noise_2D_nn_ot_gw.csv') # If 200 points simulated in the synthetic dataset\n",
    "#res.to_csv('results/results_gps_noise_2D_nn_ot_gw_small.csv') # If 50 points simulated in the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 200 points simulated in the synthetic dataset\n",
    "res = pd.read_csv('results/results_gps_noise_2D_nn_ot_gw.csv', index_col = 0)\n",
    "res_gmn = pd.read_csv('results/results_gps_noise_2D_gmn.csv', index_col = 0)\n",
    "res = pd.concat([res, res_gmn])\n",
    "\n",
    "# If 50 points simulated in the synthetic dataset\n",
    "res = pd.read_csv('results/results_gps_noise_2D_nn_ot_gw_small.csv', index_col = 0)\n",
    "res_gmn = pd.read_csv('results/results_gps_noise_2D_gmn_small.csv', index_col = 0)\n",
    "res = pd.concat([res, res_gmn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = ['NN', 'GMN', 'OT greedy', 'OT non greedy', 'GW']\n",
    "\n",
    "res['shift'] = round(res['shift'], 2)\n",
    "res['std'] = round(res['std'], 2)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "gs = gridspec.GridSpec(2, 3, figure=fig)\n",
    "gs.update(wspace = 0.1, hspace = 0.3)\n",
    "\n",
    "for i in range (len(methods)):\n",
    "    df_sub = res[res.method==methods[i]]\n",
    "    result = df_sub.pivot(index='shift', columns='std', values='accuracy')\n",
    "    ax = fig.add_subplot(gs[i//3, i%3])\n",
    "    ax.set_title(methods[i], fontsize = 14)\n",
    "    ax.set_ylabel('tree detection accuracy')\n",
    "    sns.heatmap(result, cmap='viridis', ax = ax, vmin=0, vmax=1)\n",
    "    ax.set(xlabel=\"Individual noise in ground data - sigma (m)\", ylabel = \"General noise in drone data - shift (m)\")\n",
    "\n",
    "fig.suptitle('Evaluation of Mapping Methods when Increasing Noise in GPS position of Ground and Drone Measurements\\n (Synthetic Dataset with 200 trees)', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Noise in DeepForest & GPS Position of ground data\n",
    "\n",
    "We are interested to change deepforest ability to detect trees on drone images. We modify the threshold score of the algorithm. From [Ben. G. Weinstein et al., 2019], the score_threshold is defined as the minimum probability score to be included in final boxes, ranging from 0 to 1. We increase the threshold score from 0 to 0.7 to refine the tree detection.\n",
    "\n",
    "We work on a synthetic dataset based on the drone image of the site BART from NEON dataset. More precisely, we focus on the tile number 50 (BART_050). There are 52 tree instances (ground measurements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.getcwd()\n",
    "img_path = 'NEON/evaluation/BART_050.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = deepforest.deepforest()\n",
    "test_model.use_release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 1, 11)\n",
    "for k in thresholds:\n",
    "    boxes = get_annotations(os.path.join(dir,img_path), test_model, score_threshold = k)\n",
    "    boxes.to_csv('NEON/annotations/annot_threshold_{}.csv'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rasterio.open(img_path)\n",
    "raster = src.read()\n",
    "image = reshape_as_image(raster)\n",
    "\n",
    "# Plot all points\n",
    "fig, ax = plt.subplots(1, figsize = (15,15))\n",
    "im = mpimg.imread(img_path)\n",
    "\n",
    "#ax = sns.scatterplot(x=\"x\", y=\"y\", data=df_img, s = 150, hue=\"label\", edgecolor='black',linewidth=1, palette = palette)\n",
    "ax.imshow(im)\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "im = Image.fromarray(im)\n",
    "im.save('NEON/images/BART_050.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the 52 tree instances predicted by the released version of DeepForest as the truth.\n",
    "im = cv2.imread(img_path)\n",
    "df_drone = pd.read_csv('NEON/annotations/final_annotations.csv', index_col = 0)\n",
    "df_img = df_drone[df_drone.img_path == 'BART_050.tif']\n",
    "\n",
    "df_img = df_img.reset_index(drop=True)\n",
    "df_img['tag'] = df_img.index\n",
    "\n",
    "print(len(df_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise true bounding boxes\n",
    "true_boxes = df_img[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n",
    "true_annotations = box_to_annotation(true_boxes)\n",
    "im = draw_annotations(im, true_annotations, color=(255, 0, 0), label_to_name=None, show_caption = True, cv2_authorized = False, thickness = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_ground(dfg, std):\n",
    "    n = len(dfg)\n",
    "    dfg_noisy = dfg.copy()\n",
    "    noise = np.random.normal(0, std, (n, 2))\n",
    "    dfg_noisy[['x', 'y']] = dfg[['x', 'y']] + noise\n",
    "    return dfg_noisy\n",
    "\n",
    "def get_tag(new_boxes, true_boxes):\n",
    "    X = new_boxes[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n",
    "    gt = true_boxes[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n",
    "    p = 0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        iou = []\n",
    "        for j in range(len(gt)):\n",
    "            iou.append(bb_intersection_over_union(X[i],gt[j]))\n",
    "        if np.max(iou)>0.5:\n",
    "            p += 1\n",
    "            new_boxes.loc[i,'tag'] = true_boxes.loc[np.argmax(iou),'tag']\n",
    "        else:\n",
    "            new_boxes.loc[i,'tag'] = -1\n",
    "    print('There are {} true boxes'.format(p))\n",
    "    return(new_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 1, 11)\n",
    "sigmas = np.linspace(0, 2, 11)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.getcwd()\n",
    "img_path = 'NEON/images/BART_050.tif'\n",
    "\n",
    "res = pd.DataFrame()\n",
    "\n",
    "df_ground = df_img[['x', 'y', 'tag']]\n",
    "df_drone = df_img[['xmin', 'ymin', 'xmax', 'ymax', 'x', 'y', 'tag']]\n",
    "n = len(df_ground)\n",
    "\n",
    "for k in thresholds:\n",
    "    boxes = get_annotations(os.path.join(dir,img_path), test_model, score_threshold = k)\n",
    "    \n",
    "    # Visualisation of the predicted bounding boxes\n",
    "    im = cv2.imread(img_path)\n",
    "    annotations = box_to_annotation(boxes[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy())\n",
    "    im = draw_annotations(im, annotations, color=(255, 0, 0), label_to_name=None, show_caption = True, cv2_authorized = False, thickness = 2)\n",
    "    plt.show()\n",
    "    \n",
    "    boxes = get_tag(boxes, df_drone)\n",
    "    boxes[['x', 'y']] = boxes.apply(lambda x: [(x.xmin+x.xmax)/2, (x.ymin+x.ymax)/2], axis=1, result_type=\"expand\")\n",
    "\n",
    "    print(boxes.tag.to_numpy())\n",
    "    \n",
    "    for s in range(len(sigmas)):\n",
    "        std = sigmas[s]\n",
    "        dfd_0 = boxes\n",
    "        dfg_0 = noise_ground(df_ground, std)\n",
    "        m = len(dfd_0)\n",
    "        \n",
    "        X_drone = dfd_0[['x', 'y']].to_numpy()\n",
    "        X_ground = dfg_0[['x', 'y']].to_numpy()\n",
    "        \n",
    "        X_drone_true = df_drone[['x', 'y']].to_numpy()\n",
    "        \n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(im.astype(int))\n",
    "        for i in range(len(X_drone)):\n",
    "            plt.scatter(x=X_drone[i][0], y=X_drone[i][1], c='r', s=40)\n",
    "        for i in range(len(X_drone_true)):\n",
    "            plt.scatter(x=X_drone_true[i][0], y=X_drone_true[i][1], c='k', s=100)\n",
    "        for i in range(len(X_ground)):\n",
    "            plt.scatter(x=X_ground[i][0], y=X_ground[i][1], c='b', s=40)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # Nearest Neighbours\n",
    "        dfd = dfd_0.copy()\n",
    "        dfg = dfg_0.copy()\n",
    "        X_drone_nn = np.hstack((X_drone, np.zeros((m, 1), dtype=np.int32)))\n",
    "        X_ground_nn = np.hstack((X_ground, np.zeros((n, 1), dtype=np.int32)+1))\n",
    "        idx = index_nn(X_ground_nn, X_drone_nn)\n",
    "        dfg['idx'] = idx\n",
    "        dfd['idx']= dfd.index\n",
    "        final = pd.merge(dfd, dfg, on='idx', how = 'inner', suffixes=('_d', '_g'))\n",
    "        acc = len(final[final.tag_d == final.tag_g])/n\n",
    "        new_row = {'method':'NN', 'std':std, 'deepforest_threshold':k, 'accuracy':acc}\n",
    "        #append row to the dataframe\n",
    "        res = res.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "        # OT ground to drone\n",
    "        dfd = dfd_0.copy()\n",
    "        dfg = dfg_0.copy()\n",
    "        G = OT_sinkhorn(X_drone, X_ground, lambd = 0.01)\n",
    "        idx = np.argmax(G, axis = 0)\n",
    "        dfg['idx'] = idx\n",
    "        dfd['idx']= dfd.index\n",
    "        final = pd.merge(dfd, dfg, on='idx', how = 'inner', suffixes=('_d', '_g'))\n",
    "        acc = len(final[final.tag_d == final.tag_g])/n\n",
    "        new_row = {'method':'OT non greedy', 'std':std, 'deepforest_threshold':k, 'accuracy':acc}\n",
    "        #append row to the dataframe\n",
    "        res = res.append(new_row, ignore_index=True)\n",
    "\n",
    "        # OT greedy\n",
    "        dfd = dfd_0.copy()\n",
    "        dfg = dfg_0.copy()\n",
    "        G = OT_sinkhorn(X_drone, X_ground, lambd = 0.01)\n",
    "        cost = -G*10e4\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        df_left = dfd.loc[row_ind]\n",
    "        df_left['idx']= col_ind\n",
    "        dfg['idx'] = dfg.index\n",
    "        final = pd.merge(df_left, dfg, on='idx', how = 'inner', suffixes=('_d', '_g')) \n",
    "        acc = len(final[final.tag_d == final.tag_g])/n\n",
    "        new_row = {'method':'OT greedy', 'std':std, 'deepforest_threshold':k, 'accuracy':acc}\n",
    "        #append row to the dataframe\n",
    "        res = res.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "        # Gromov-Wasserstein\n",
    "        G = gromov_wasserstein(X_drone, X_ground)\n",
    "        idx = np.argmax(G, axis = 0)\n",
    "        dfg['idx'] = idx\n",
    "        dfd['idx']= dfd.index\n",
    "        final = pd.merge(dfd, dfg, on='idx', how = 'inner', suffixes=('_d', '_g'))\n",
    "        print(final)\n",
    "        acc = len(final[final.tag_d == final.tag_g])/n\n",
    "        new_row = {'method':'GW', 'std':std, 'deepforest_threshold':k, 'accuracy':acc}\n",
    "        #append row to the dataframe\n",
    "        res = res.append(new_row, ignore_index=True)\n",
    "\n",
    "        print(res)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.to_csv('NEON/evaluation/results_gps_deepforest_noise_nn_ot_gw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('NEON/evaluation/results_gps_deepforest_noise_nn_ot_gw.csv', index_col = 0)\n",
    "res_gmn = pd.read_csv('NEON/evaluation/results_gps_deepforest_noise_gmn.csv', index_col = 0)\n",
    "res = pd.concat([res, res_gmn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['NN', 'GMN', 'OT greedy', 'OT non greedy', 'GW']\n",
    "\n",
    "res['deepforest_threshold'] = round(res['deepforest_threshold'], 2)\n",
    "res['std'] = round(res['std'], 2)\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "gs = gridspec.GridSpec(2, 3, figure=fig)\n",
    "gs.update(wspace = 0.1, hspace = 0.3)\n",
    "\n",
    "for i in range (len(methods)):\n",
    "    df_sub = res[res.method==methods[i]]\n",
    "    result = df_sub.pivot(index='deepforest_threshold', columns='std', values='accuracy')\n",
    "    ax = fig.add_subplot(gs[i//3, i%3])\n",
    "    ax.set_title(methods[i], fontsize = 14)\n",
    "    sns.heatmap(result, cmap='viridis', ax = ax, vmin=0, vmax=1)\n",
    "    ax.set(xlabel=\"Individual noise in ground data - sigma (m)\", ylabel = \"Deepforest threshold to keep boxes\")\n",
    "\n",
    "fig.suptitle('Evaluation of mapping methods when increasing noise in GPS position of ground measurements and tree detection threshold of DeepForest\\n (Synthetic Dataset on BART_050 (NEON) with 50 ground measuremnts)', fontsize = 16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}